# ðŸš€ Quick Start Guide - Local RAG System

## Zero Installation - SQLite Version!

## Step-by-Step Setup

### âœ… STEP 1: Install Python Dependencies

```bash
cd "c:\Users\sandeepk\Favorites\AGENT PRac\RAG"
pip install -r requirements.txt
```

This installs:

- `pypdf` - PDF text extraction
- `sentence-transformers` - FREE embedding model
- `python-dotenv` - Environment variables

**Expected time:** 1-2 minutes
**Note:** SQLite comes with Python - no database installation needed!

---

### âœ… STEP 2: Install Ollama (LLM)

1. Download: https://ollama.ai
2. Install Ollama
3. Pull a model:

```bash
ollama pull mistral
```

**Alternative models:**

```bash
ollama pull llama2        # Faster, less accurate
ollama pull phi           # Smallest (2GB)
ollama pull mixtral       # Best quality (larger)
```

---

### âœ… STEP 3: Setup Database (Optional)

```bash
python setup_database.py
```

This creates the SQLite database file `rag_database.db` with the documents table.
**Note:** The database is created automatically when you run main.py, so this step is optional.

---

### âœ… STEP 4: Test the System

```bash
python main.py
```

**Interactive Menu:**

```
1. Ingest PDF       â† Start here
2. Ask Question     â† Query your documents
3. Show Statistics  â† View system info
4. Clear Database   â† Reset if needed
5. Exit
```

---

## ðŸŽ¯ Your First RAG Query

### 1. Prepare a PDF

- Find any PDF document
- Place it in your workspace
- Example: `sample.pdf`

### 2. Run the system

```bash
python main.py
```

### 3. Ingest the PDF

- Select option `1` (Ingest PDF)
- Enter PDF path: `sample.pdf`
- Wait for processing (~10-30 seconds)

### 4. Ask Questions

- Select option `2` (Ask Question)
- Type your question
- Get answer with sources!

---

## ðŸ“‹ Example Session

```
ðŸš€ Local RAG System
============================================================

Options:
  1. Ingest PDF
  2. Ask Question
  3. Show Statistics
  4. Clear Database
  5. Exit

Select option (1-5): 1

Enter PDF file path: sample.pdf

ðŸ“¥ INGESTING PDF: sample.pdf
============================================================
ðŸ“„ Loading PDF: sample.pdf
   Pages: 10
âœ… Extracted 45,230 characters from PDF
âœ… Created 95 chunks (size=500, overlap=50)
ðŸ”„ Generating embeddings...
âœ… Successfully ingested 95 chunks
ðŸ“Š Total documents in DB: 95

Select option (1-5): 2

Enter your question: What is the main topic of this document?

â“ QUERY: What is the main topic of this document?
============================================================
ðŸ”„ Embedding question...
ðŸ” Searching for top 5 similar documents...
âœ… Found 5 relevant documents
ðŸ¤– Generating answer...

============================================================
ðŸ’¡ ANSWER:
Based on the provided context, this document discusses...
============================================================
```

---

## ðŸ”§ Troubleshooting

### Ollama Not Found

```bash
# Check installation
ollama --version

# Add to PATH if needed
```

### Python Import Errors

```bash
# Reinstall dependencies
pip install --upgrade -r requirements.txt
```

### Database File Permission Error

The SQLite file is created automatically in your project folder. If you get permission errors, run as administrator or check folder permissions.

---

## ðŸ’¡ What You've Built

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              YOUR LOCAL RAG SYSTEM                  â”‚
â”‚              (Zero Installation!)                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                     â”‚
â”‚  PDF â†’ pypdf (text extraction)                      â”‚
â”‚         â†“                                           â”‚
â”‚  Text â†’ Python chunking (500 chars)                 â”‚
â”‚         â†“                                           â”‚
â”‚  Chunks â†’ sentence-transformers (embeddings)        â”‚
â”‚         â†“                                           â”‚
â”‚  Vectors â†’ sentence-transformers (384-dim)          â”‚
â”‚         â†“                                           â”‚
â”‚  Storage â†’ SQLite (rag_database.db)                 â”‚
â”‚         â†“                                           â”‚
â”‚  Query â†’ Cosine similarity (Python calculation)     â”‚
â”‚         â†“                                           â”‚
â”‚  Context â†’ Ollama (LLM generation)                  â”‚
â”‚         â†“                                           â”‚
â”‚  Answer + Sources                                   â”‚
â”‚                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸŽ“ Key Concepts

### 1. **Embeddings**

- Converts text â†’ 384-dim vectors
- Similar text = similar vectors
- Model: `all-MiniLM-L6-v2` (FREE)

### 2. **Vector Search**

```python
# Manual cosine similarity calculation
def cosine_similarity(vec1, vec2):
    dot_product = sum(a * b for a, b in zip(vec1, vec2))
    magnitude1 = sqrt(sum(a * a for a in vec1))
    magnitude2 = sqrt(sum(b * b for b in vec2))
    return dot_product / (magnitude1 * magnitude2)
```

Iterates through all stored vectors and finds the most similar ones.

### 3. **RAG Pattern**

1. Retrieve relevant context (similarity search)
2. Augment LLM prompt (add context to question)
3. Generate answer (Ollama with context)

---

## ðŸš€ Next Steps

1. âœ… **Test with your own PDFs**
2. âœ… **Try different questions**
3. âœ… **Experiment with chunk sizes**
4. âœ… **Try different LLM models**
5. âœ… **For large datasets (>10k docs), upgrade to PostgreSQL + pgvector**

---

## ðŸ“š Files Created

- `config.py` - Configuration management
- `database.py` - SQLite operations with manual similarity
- `embeddings.py` - Sentence-transformers wrapper
- `pdf_loader.py` - PDF text extraction
- `chunking.py` - Text splitting with overlap
- `llm.py` - Ollama LLM integration
- `rag_pipeline.py` - Main orchestration
- `setup_database.py` - Database setup (optional)
- `main.py` - Interactive CLI
- `requirements.txt` - Python dependencies (only 3!)
- `.env.example` - Configuration template

---

**ðŸŽ‰ You now have a production-grade RAG system running locally!**

No API keys, no cloud costs, complete control.
